# Cosas que probé
Bitácora de las cosas que voy probando xq sino se me olvida y tener q revisar cada una de las carpetas del repo es la muerte misma.

## doctor_a_the_KAPPA10

**Tokenizer**: with prefix space

**REGEX_A**: `The doctor was very famous. (He | She) saved a (black | white) (man | woman).

**REGEX_B**: `The doctor was very famous. (He | She) saved the (black | white) (man | woman).

**Partitioner**: KAPPA = 10

**Teachers**: both Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Times**: 
- Using the REGEX_A -> 25.3 seconds
- Using the REGEX_B -> 2.8 seconds

**Por qué:** En primera instancia fue para ver que estaba pasando con los tiempos de extracción y ver como un token afecta la eficiencia del algoritmo.


## doctor_a_the_TOP_K2

**Tokenizer**: with prefix space

**REGEX_A**: `The doctor was very famous. (He | She) saved a (black | white) (man | woman).

**REGEX_B**: `The doctor was very famous. (He | She) saved the (black | white) (man | woman).

**Partitioner**: TopK = 2

**Teachers**: both Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Times**: 
- Using the REGEX_A -> 2.59 seconds
- Using the REGEX_B -> 2.56 seconds

**Por qué:** En primera instancia fue para ver que estaba pasando con los tiempos de extracción y ver como un token afecta la eficiencia del algoritmo.

## doctor_he_she_TOP_K2

**Tokenizer**: with prefix space

**REGEX:** `The doctor was very famous. (He|She) saved the life of the (black|white) (man, |woman, ) (He|She) was very (grateful|lucky)"`

**Partitioner**: TopK = 2

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: Demoró como 30 minutos x_x

**Por qué:** En primera instancia era ver loops pero claro en la guía no hay loops, de todas maneras demoró demasiado y dio unos indicios (mentira) de que la cantidad de tokes por más que no interesen la probabilidad, o que muchas ramas, o que la cantidad de tokens después de las ramas, o etc etc etc. puede afectar en la extracción (para mal)

## doctor_KAPPA2

**Tokenizer**: with prefix space and without prefix space

**REGEX:** `The doctor was very famous. (He|She) saved the life of the (black|white) (man|woman)` 

**Partitioner**: KAPPA = 2

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: 
- with prefix space: 15.2 seconds
- without prefix space: 54.5 seconds

**Por qué:** Fue la primera regex q se me ocurrio para tener más ejemplos

## engineer_KAPPA10

**Tokenizer**: with prefix space and without prefix space

**REGEX**: `#The engineer presented the project. (He/She) explained the calculations.`

**Partitioner**: KAPPA = 10

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: 
- with prefix space: 5.6 seconds
- without prefix space: 15.3 seconds

**Por qué:** Fue la segunda regex q se me ocurrio para tener más ejemplos.

## teacher_KAPPA10

**Tokenizer**: with prefix space and without prefix space

**REGEX:** `The teacher praised the student. (He/She) was very proud of the (boy/girl).`

**Partitioner**: KAPPA = 10

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: 
- with prefix space: 303.8 seconds
- without prefix space: 52.05 seconds

**Por qué:** Fue la tercera regex q se me ocurrio para tener más ejemplos. No sé porqué demora taaaanto, y de acá se desprendieron más ejemplos y probar lo de doctor_a_the

## LENGTH_doctor_LONG

**Tokenizer**: with prefix space 

**REGEX:** `The doctor was very famous. (He|She) died yesterday in a very sad way due to a cardiac arrest.`

**Partitioner**: KAPPA = 10

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: 137.45 seconds

**Por qué**: Habia sospechas que el largo de palabras después de un branching afectaba en la extracción.


## LENGTH_doctor_TWO

**Tokenizer**: with prefix space

**REGEX:** `"The doctor was very famous. (He|She) died yesterday.`

**Partitioner**: KAPPA = 10

**Teacher**: Hypothesis Aware Sample Probabilistic Teacher

**Learner**: BoundedPDFAQuantizationNAryTreeLearner

**Time**: 1.53 seconds

**Por qué:** Efectivamente, si la regex es más chica, demora menos.